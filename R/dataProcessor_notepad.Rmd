
TYP DANYCH

Korzystamy z danych z poprzedniego etapu.

```{r}
data <- read.csv(file = "../data/energy_data_after_analysis.csv", stringsAsFactors = FALSE)
data <- subset(data, select = -c(X) )
str(data)
```

WARTOŚCI BRAKUJĄCE - usunieie

```{r}
# w ilu kolumnach brakuje danych
which(is.na(data))
# ile jest łącznie brakujących danych
sum(is.na(data))
mising<-data[is.na(data),]
data = na.omit(data)
```
Sprowadzenie atrybutów których rozkład odbiega od rozkładu normalnego do rozkładu normalnego przy pomocy Box-Cox

```{r}
library(lubridate)
library(corrplot)
library(Hmisc)
library(MASS)

b<-boxcox(lm(data$Appliances ~ 1))
lambda <- b$x[which.max(b$y)]
print(lambda)
data$logAppliances = (data$Appliances ^ lambda - 1) / lambda

b<-boxcox(lm(data$Visibility ~ 1))
lambda <- b$x[which.max(b$y)]
print(lambda)
data$logVisibility = (data$Visibility ^ lambda - 1) / lambda

data$Windspeed <- rep(1e-5,length(data$Windspeed))+data$Windspeed
b<-boxcox(lm(data$Windspeed ~ 1))
lambda <- b$x[which.max(b$y)]
print(lambda)
data$logWindspeed = (data$Windspeed ^ lambda - 1) / lambda

data$Tdewpoint <- rep(1e-5+abs(min(data$Tdewpoint)),length(data$Tdewpoint))+data$Tdewpoint
b<-boxcox(lm(data$Tdewpoint ~ 1))
lambda <- b$x[which.max(b$y)]
print(lambda)
data$logTdewpoint = (data$Tdewpoint ^ lambda - 1) / lambda

b<-boxcox(lm(data$T9 ~ 1))
lambda <- b$x[which.max(b$y)]
print(lambda)
data$logT9 = (data$T9 ^ lambda - 1) / lambda

b<-boxcox(lm(data$T3 ~ 1))
lambda <- b$x[which.max(b$y)]
print(lambda)
data$logT3 = (data$T3 ^ lambda - 1) / lambda

b<-boxcox(lm(data$T4 ~ 1))
lambda <- b$x[which.max(b$y)]
print(lambda)
data$logT4 = (data$T4 ^ lambda - 1) / lambda

b<-boxcox(lm(data$T5 ~ 1))
lambda <- b$x[which.max(b$y)]
print(lambda)
data$logT5 = (data$T5 ^ lambda - 1) / lambda

```

Dla nowo powstalych atrybutów zlogarytmowanych sprawdzamy korelacje z kolumna logAppliances.


```{r}

res <- cor(data, use = "complete.obs")
res[is.na(res)] = 0
res <- round(res, 2)
corrplot(res, type = "full", order = "hclust",
         tl.col = "black")

print(data.frame(res["logAppliances",]))

```


Dokonujemy selekcji artybutów bazując na korelacji z logAppliances.

```{r}
corr<-data.frame(res["logAppliances",])
print(abs(corr)<=0.1)

atributes <- data[,!names(data) %in% c("Appliances","Tdewpoint","T5","T4","T3","T9","Rh_out","Windspeed","Visibility","rv1", "rv2")]
# w ilu kolumnach brakuje danych
colSums(is.na(atributes))
```

Algorytm Boruta do dalszej analizy przydatności atrybutóW.

```{r}
boruta_atributes = atributes
str(boruta_atributes)
library(Boruta)

set.seed(42)
boruta.train <- Boruta(logAppliances~., data = boruta_atributes, doTrace = 2)

print(boruta.train)

final.train <- TentativeRoughFix(boruta.train)
print(final.train)

plot(final.train, xlab = "", xaxt = "n")
lz<-lapply(1:ncol(final.train$ImpHistory),function(i)
final.train$ImpHistory[is.finite(final.train$ImpHistory[,i]),i])
names(lz) <- colnames(final.train$ImpHistory)
Labels <- sort(sapply(lz,median))
axis(side = 1,las=2,labels = names(Labels), at = 1:ncol(final.train$ImpHistory), cex.axis = 0.7)
```


```{r}
write.csv(atributes, '../data/energy_data_after_processing.csv')
```

Stworzenie i zapisanie zbiorów testowych i treningowych

```{r}
library(caret)
dt = sort(sample(nrow(atributes), nrow(atributes)*.8))
train<-atributes[dt,]
test<-atributes[-dt,]
train_par<-preProcess(train)
train<-predict(train_par,train)
test<-predict(train_par,test)
```


```{r}
write.csv(train, '../data/energy_data_train.csv')
write.csv(test, '../data/energy_data_test.csv')
```

