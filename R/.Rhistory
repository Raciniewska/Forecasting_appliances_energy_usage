test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances,RH_6, RH_7, RH_out) )
x = as.matrix(train_attributes)
y_train = train$logAppliances
x_test = as.matrix(test_attributes)
y_test = test$logAppliances
lambdas <- 10^seq(2, -3, by = -.05)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
plot(cv_ridge)
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = 1e-07)
summary(ridge_reg)
coef(ridge_reg)
library(glmnet)
train_attributes <- subset(train, select = -c(logAppliances, RH_6, RH_7, RH_out) )
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances,RH_6, RH_7, RH_out) )
x = as.matrix(train_attributes)
y_train = train$logAppliances
x_test = as.matrix(test_attributes)
y_test = test$logAppliances
lambdas <- 10^seq(2, -3, by = -.05)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
plot(cv_ridge)
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = 1e-07)
summary(ridge_reg)
coef(ridge_reg)
# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
res<-eval_results(y_train, predictions_train, train)
print(res)
# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
res<-eval_results(y_test, predictions_test, test)
print(res)
library(glmnet)
train_attributes <- subset(train, select = -c(logAppliances, RH_6, RH_7, RH_out) )
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances,RH_6, RH_7, RH_out) )
x = as.matrix(train_attributes)
y_train = train$logAppliances
x_test = as.matrix(test_attributes)
y_test = test$logAppliances
lambdas <- 10^seq(2, -3, by = -.05)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
plot(cv_ridge)
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = 1e-07)
summary(ridge_reg)
coef(ridge_reg)
# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
res<-eval_results(y_train, predictions_train, train)
print(res)
# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
res<-eval_results(y_test, predictions_test, test)
print(res)
library(glmnet)
x = as.matrix(train_attributes)
y_train = train$logAppliances
x_test = as.matrix(test_attributes)
y_test = test$logAppliances
lambdas <- 10^seq(2, -3, by = -.05)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
plot(cv_ridge)
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = 1e-07)
summary(ridge_reg)
coef(ridge_reg)
library(glmnet)
x = as.matrix(train_attributes)
y_train = train$logAppliances
x_test = as.matrix(test_attributes)
y_test = test$logAppliances
lambdas <- 10^seq(2, -3, by = -.05)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
plot(cv_ridge)
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = 1e-07)
summary(ridge_reg)
coef(ridge_reg)
library(glmnet)
x = as.matrix(train_attributes)
y_train = train$logAppliances
x_test = as.matrix(test_attributes)
y_test = test$logAppliances
cv_ridge <- cv.glmnet(x, y_train, alpha = 0)
optimal_lambda <- cv_ridge$lambda.min
print(optimal_lambda)
plot(cv_ridge)
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = 1e-07)
summary(ridge_reg)
coef(ridge_reg)
library(glmnet)
x = as.matrix(train_attributes)
y_train = train$logAppliances
x_test = as.matrix(test_attributes)
y_test = test$logAppliances
lambdas <- 10^seq(2, -3, by = -.05)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
plot(cv_ridge)
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = 1e-07)
summary(ridge_reg)
coef(ridge_reg)
library(glmnet)
x = as.matrix(train_attributes)
y_train = train$logAppliances
x_test = as.matrix(test_attributes)
y_test = test$logAppliances
lambdas <- 10^seq(2, -3, by = -.05)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
plot(lambdas,cv_ridge$cvm)
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = 1e-07)
summary(ridge_reg)
coef(ridge_reg)
library(glmnet)
x = as.matrix(train_attributes)
y_train = train$logAppliances
x_test = as.matrix(test_attributes)
y_test = test$logAppliances
lambdas <- 10^seq(2, -3, by = -.05)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
plot(lambdas,cv_ridge$cvm,ylab="Mean-Squared Error")
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = 1e-07)
summary(ridge_reg)
coef(ridge_reg)
library(glmnet)
x = as.matrix(train_attributes)
y_train = train$logAppliances
x_test = as.matrix(test_attributes)
y_test = test$logAppliances
lambdas <- 10^seq(2, -3, by = -.05)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
plot(lambdas,cv_ridge$cvm,ylab="Mean-Squared Error",  type="l")
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = 1e-07)
summary(ridge_reg)
coef(ridge_reg)
library(glmnet)
x = as.matrix(train_attributes)
y_train = train$logAppliances
x_test = as.matrix(test_attributes)
y_test = test$logAppliances
lambdas <- 10^seq(2, -3, by = -.05)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
plot(lambdas,cv_ridge$cvm,ylab="Mean-Squared Error",ylab="Lambda",  type="l")
library(glmnet)
x = as.matrix(train_attributes)
y_train = train$logAppliances
x_test = as.matrix(test_attributes)
y_test = test$logAppliances
lambdas <- 10^seq(2, -3, by = -.05)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
plot(lambdas,cv_ridge$cvm,ylab="Mean-Squared Error",xlab="Lambda",  type="l")
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = 1e-07)
summary(ridge_reg)
coef(ridge_reg)
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights) )
train_attributes <- subset(train, select = -c(logAppliances) )
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances) )
logAppliances<-train$logAppliances
train <- cbind(train_attributes, logAppliances)
library(glmnet)
x = as.matrix(train_attributes)
y_train = train$logAppliances
x_test = as.matrix(test_attributes)
y_test = test$logAppliances
lambdas <- 10^seq(2, -3, by = -.05)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
plot(lambdas,cv_ridge$cvm,ylab="Mean-Squared Error",xlab="Lambda",  type="l")
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = 1e-07)
summary(ridge_reg)
coef(ridge_reg)
eval_results <- function(true, predicted, df) {
SSE <- sum((predicted - true)^2)
SST <- sum((true - mean(true))^2)
R_square <- 1 - SSE / SST
RMSE = sqrt(SSE/nrow(df))
return(data.frame(
RMSE = RMSE,
Rsquare = R_square
))}
# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
res<-eval_results(y_train, predictions_train, train)
print(res)
# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
res<-eval_results(y_test, predictions_test, test)
print(res)
thresh_vals = list(10^(-10),10^(-9),10^(-8),10^(-7),10^(-6), 10^(-5), 10^(-4), 10^(-3), 10^(-2), 10^(-1), 10^(-0))
train_rsme=list()
test_rsme=list()
test_r2=list()
train_r2=list()
for(i in 1:length(thresh_vals)){
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = thresh_vals[i])
# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
ret<-eval_results(y_train, predictions_train, train)
train_r2=append(train_r2, ret$Rsquare)
train_rsme=append(train_rsme, ret$RMSE)
# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
ret<-eval_results(y_test, predictions_test, test)
test_r2=append(test_r2, ret$Rsquare)
test_rsme=append(test_rsme, ret$RMSE)
}
plot(seq(-10,0,1) ,train_r2 ,pch=19, xlab="log10 thresh")
plot(seq(-10,0,1) ,test_r2 ,pch=19, xlab="log10 thresh")
plot(seq(-10,0,1) ,test_rsme ,pch=19, xlab="log10 thresh")
plot(seq(-10,0,1) ,train_rsme ,pch=19, xlab="log10 thresh")
thresh_vals = list(10^(-10),10^(-9),10^(-8),10^(-7),10^(-6), 10^(-5), 10^(-4), 10^(-3), 10^(-2), 10^(-1), 10^(-0))
train_rsme=list()
test_rsme=list()
test_r2=list()
train_r2=list()
for(i in 1:length(thresh_vals)){
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = thresh_vals[i])
# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
ret<-eval_results(y_train, predictions_train, train)
train_r2=append(train_r2, ret$Rsquare)
train_rsme=append(train_rsme, ret$RMSE)
# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
ret<-eval_results(y_test, predictions_test, test)
test_r2=append(test_r2, ret$Rsquare)
test_rsme=append(test_rsme, ret$RMSE)
}
plot(seq(-10,0,1) ,train_r2 ,pch=19, xlab="log10 thresh", type="l")
plot(seq(-10,0,1) ,test_r2 ,pch=19, xlab="log10 thresh", type="l")
plot(seq(-10,0,1) ,test_rsme ,pch=19, xlab="log10 thresh", type="l")
plot(seq(-10,0,1) ,train_rsme ,pch=19, xlab="log10 thresh", type="l")
thresh_vals = list(10^(-10),10^(-9),10^(-8),10^(-7),10^(-6), 10^(-5), 10^(-4), 10^(-3), 10^(-2), 10^(-1), 10^(-0))
train_rsme=list()
test_rsme=list()
test_r2=list()
train_r2=list()
for(i in 1:length(thresh_vals)){
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = thresh_vals[i])
# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
ret<-eval_results(y_train, predictions_train, train)
train_r2=append(train_r2, ret$Rsquare)
train_rsme=append(train_rsme, ret$RMSE)
# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
ret<-eval_results(y_test, predictions_test, test)
test_r2=append(test_r2, ret$Rsquare)
test_rsme=append(test_rsme, ret$RMSE)
}
plot(seq(-10,0,1) ,train_r2 ,pch=19, xlab="log10(thresh)", type="l")
plot(seq(-10,0,1) ,test_r2 ,pch=19, xlab="log10(thresh)", type="l")
plot(seq(-10,0,1) ,test_rsme ,pch=19, xlab="log10(thresh)", type="l")
plot(seq(-10,0,1) ,train_rsme ,pch=19, xlab="log10(thresh)", type="l")
library(glmnet)
train_attributes <- subset(train, select = -c(logAppliances, RH_6, RH_7, RH_out) )
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances,RH_6, RH_7, RH_out) )
x = as.matrix(train_attributes)
y_train = train$logAppliances
x_test = as.matrix(test_attributes)
y_test = test$logAppliances
lambdas <- 10^seq(2, -3, by = -.05)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
plot(cv_ridge)
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = 1e-07)
summary(ridge_reg)
coef(ridge_reg)
# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
res<-eval_results(y_train, predictions_train, train)
print(res)
# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
res<-eval_results(y_test, predictions_test, test)
print(res)
library(glmnet)
train_attributes <- subset(train, select = -c(logAppliances, RH_6, RH_7, RH_out) )
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances,RH_6, RH_7, RH_out) )
x = as.matrix(train_attributes)
y_train = train$logAppliances
x_test = as.matrix(test_attributes)
y_test = test$logAppliances
lambdas <- 10^seq(2, -3, by = -.05)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
plot(lambdas,cv_ridge$cvm,ylab="Mean-Squared Error",xlab="Lambda",  type="l")
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = optimal_lambda,thresh = 1e-07)
summary(ridge_reg)
coef(ridge_reg)
# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
res<-eval_results(y_train, predictions_train, train)
print(res)
# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
res<-eval_results(y_test, predictions_test, test)
print(res)
install.packages("randomForest")
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights) )
train_attributes <- subset(train, select = -c(logAppliances) )
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances) )
logAppliances<-train$logAppliances
train <- cbind(train_attributes, logAppliances)
library(randomForest)
urlPackage <-"https://cran.r-project.org/src/contrib/Archive/randomForest/randomForest_4.7-1.tar.gz"
install.packages(urlPackage, repos=NULL, type="source")
library(randomForest)
R
urlPackage <-"https://cran.r-project.org/src/contrib/Archive/randomForest/randomForest_4.6-14.tar.gz"
install.packages(urlPackage, repos=NULL, type="source")
library(randomForest)
install.packages("Rtools")
urlPackage <-"https://cran.r-project.org/src/contrib/Archive/randomForest/randomForest_4.6-14.tar.gz"
install.packages(urlPackage, repos=NULL, type="source")
library(randomForest)
library(Rtools)
install.packages("Rtools")
install.packages("installr")
library(installr)
updateR()
library(e1071)
model = svm(logAppliances ~ ., data = train)
print(model)
hyper_grid <- expand.grid(
gamma       = seq(0.01, 0.3, by = 0.05),
epsilon     = seq(0.1, 0.9, by = 0.1),
cost        = seq(1,100,by=10),
OOB_RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
hyper_grid <- expand.grid(
gamma       = seq(0.01, 0.3, by = 0.05),
epsilon     = seq(0.1, 0.9, by = 0.1),
cost        = seq(1,100,by=50),
OOB_RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
hyper_grid <- expand.grid(
gamma       = seq(0.01, 0.3, by = 0.07),
epsilon     = seq(0.1, 0.9, by = 0.1),
cost        = seq(1,100,by=50),
OOB_RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
hyper_grid <- expand.grid(
gamma       = seq(0.01, 0.3, by = 0.07),
epsilon     = seq(0.1, 0.9, by = 0.15),
cost        = seq(1,100,by=50),
OOB_RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
hyper_grid <- expand.grid(
gamma       = seq(0.01, 0.3, by = 0.07),
epsilon     = seq(0.1, 0.9, by = 0.15),
cost        = seq(1,100,by=20),
OOB_RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
hyper_grid <- expand.grid(
gamma       = seq(0.01, 0.3, by = 0.07),
epsilon     = seq(0.1, 0.9, by = 0.2),
cost        = seq(1,100,by=20),
OOB_RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
hyper_grid <- expand.grid(
gamma       = seq(0.01, 0.3, by = 0.08),
epsilon     = seq(0.1, 0.9, by = 0.2),
cost        = seq(1,100,by=20),
OOB_RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
library(ranger)
# hyperparameter grid search
hyper_grid <- expand.grid(
mtry       = seq(3, 17, by = 2),
node_size  = seq(3, 9, by = 2),
replace = c(TRUE, FALSE),
ntry = seq(500,600,by=100),
RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
library(ranger)
# hyperparameter grid search
hyper_grid <- expand.grid(
mtry       = seq(3, 17, by = 2),
node_size  = seq(3, 9, by = 2),
replace = c(TRUE, FALSE),
ntry = seq(500,600,by=100),
OOB_RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
hyper_grid <- expand.grid(
gamma       = seq(0.01, 0.3, by = 0.08),
epsilon     = seq(0.1, 0.9, by = 0.2),
cost        = seq(1,100,by=20),
RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
hyper_grid <- expand.grid(
gamma       = seq(0.01, 0.3, by = 0.08),
epsilon     = seq(0.1, 0.9, by = 0.25),
cost        = seq(1,100,by=20),
RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
for(i in 1:nrow(hyper_grid)) {
# train model
model <- svm(logAppliances ~ ., data = train,
gamma = hyper_grid$gamma[i],
epsilon = hyper_grid$epsilon[i],
cost = hyper_grid$cost[i])
y_pred_train = predict(model, newdata = train_attributes)
hyper_grid$RMSE[i] <- rmse(y_pred_train,train$logAppliances)
}
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights) )
train_attributes <- subset(train, select = -c(logAppliances) )
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances) )
logAppliances<-train$logAppliances
train <- cbind(train_attributes, logAppliances)
hyper_grid <- expand.grid(
gamma       = seq(0.01, 0.3, by = 0.08),
epsilon     = seq(0.1, 0.9, by = 0.25),
cost        = seq(1,100,by=20),
RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
for(i in 1:nrow(hyper_grid)) {
# train model
model <- svm(logAppliances ~ ., data = train,
gamma = hyper_grid$gamma[i],
epsilon = hyper_grid$epsilon[i],
cost = hyper_grid$cost[i])
y_pred_train = predict(model, newdata = train_attributes)
hyper_grid$RMSE[i] <- rmse(y_pred_train,train$logAppliances)
}
install.packages("Metrics")
libary(Metrix)
library(Metrix)
library(Metrics)
for(i in 1:nrow(hyper_grid)) {
# train model
model <- svm(logAppliances ~ ., data = train,
gamma = hyper_grid$gamma[i],
epsilon = hyper_grid$epsilon[i],
cost = hyper_grid$cost[i])
y_pred_train = predict(model, newdata = train_attributes)
hyper_grid$RMSE[i] <- rmse(y_pred_train,train$logAppliances)
}
hyper_grid <- hyper_grid[order(hyper_grid$RMSE),]
print(hyper_grid)
model <- svm(logAppliances ~ ., data = train,
gamma = 0.25,
epsilon =0.1,
cost = 81)
y_pred_train = predict(model, newdata = train_attributes)
#treningowe dane
y_pred_train = predict(model, newdata = train_attributes)
res<-eval_results(train$logAppliances, y_pred_train, train)
print(res)
#testowe dane
y_pred_test = predict(model, newdata = test_attributes)
res<-eval_results(test$logAppliances,y_pred_test, test)
print(res)
seq(0.01, 0.3, by = 0.08)
seq(0.1, 0.9, by = 0.25)
seq(1,100,by=20)
