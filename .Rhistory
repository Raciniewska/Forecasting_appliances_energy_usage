# hyperparameter grid search
hyper_grid <- expand.grid(
mtry       = seq(3, 17, by = 2),
node_size  = seq(3, 9, by = 2),
replace = c(TRUE, FALSE),
ntry = seq(500,600,by=100),
RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
library(ranger)
# hyperparameter grid search
hyper_grid <- expand.grid(
mtry       = seq(3, 17, by = 2),
node_size  = seq(3, 9, by = 2),
replace = c(TRUE, FALSE),
ntry = seq(500,600,by=100),
OOB_RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
hyper_grid <- expand.grid(
gamma       = seq(0.01, 0.3, by = 0.08),
epsilon     = seq(0.1, 0.9, by = 0.2),
cost        = seq(1,100,by=20),
RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
hyper_grid <- expand.grid(
gamma       = seq(0.01, 0.3, by = 0.08),
epsilon     = seq(0.1, 0.9, by = 0.25),
cost        = seq(1,100,by=20),
RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
for(i in 1:nrow(hyper_grid)) {
# train model
model <- svm(logAppliances ~ ., data = train,
gamma = hyper_grid$gamma[i],
epsilon = hyper_grid$epsilon[i],
cost = hyper_grid$cost[i])
y_pred_train = predict(model, newdata = train_attributes)
hyper_grid$RMSE[i] <- rmse(y_pred_train,train$logAppliances)
}
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights) )
train_attributes <- subset(train, select = -c(logAppliances) )
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances) )
logAppliances<-train$logAppliances
train <- cbind(train_attributes, logAppliances)
hyper_grid <- expand.grid(
gamma       = seq(0.01, 0.3, by = 0.08),
epsilon     = seq(0.1, 0.9, by = 0.25),
cost        = seq(1,100,by=20),
RMSE   = 0
)
# total number of combinations
nrow(hyper_grid)
for(i in 1:nrow(hyper_grid)) {
# train model
model <- svm(logAppliances ~ ., data = train,
gamma = hyper_grid$gamma[i],
epsilon = hyper_grid$epsilon[i],
cost = hyper_grid$cost[i])
y_pred_train = predict(model, newdata = train_attributes)
hyper_grid$RMSE[i] <- rmse(y_pred_train,train$logAppliances)
}
install.packages("Metrics")
libary(Metrix)
library(Metrix)
library(Metrics)
for(i in 1:nrow(hyper_grid)) {
# train model
model <- svm(logAppliances ~ ., data = train,
gamma = hyper_grid$gamma[i],
epsilon = hyper_grid$epsilon[i],
cost = hyper_grid$cost[i])
y_pred_train = predict(model, newdata = train_attributes)
hyper_grid$RMSE[i] <- rmse(y_pred_train,train$logAppliances)
}
hyper_grid <- hyper_grid[order(hyper_grid$RMSE),]
print(hyper_grid)
model <- svm(logAppliances ~ ., data = train,
gamma = 0.25,
epsilon =0.1,
cost = 81)
y_pred_train = predict(model, newdata = train_attributes)
#treningowe dane
y_pred_train = predict(model, newdata = train_attributes)
res<-eval_results(train$logAppliances, y_pred_train, train)
print(res)
#testowe dane
y_pred_test = predict(model, newdata = test_attributes)
res<-eval_results(test$logAppliances,y_pred_test, test)
print(res)
seq(0.01, 0.3, by = 0.08)
seq(0.1, 0.9, by = 0.25)
seq(1,100,by=20)
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights) )
train_attributes <- subset(train, select = -c(logAppliances) )
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances) )
logAppliances<-train$logAppliances
train <- cbind(train_attributes, logAppliances)
model <- svm(logAppliances ~ ., data = train,
gamma = 0.25,
epsilon =0.1,
cost = 81)
library(e1071)
model = svm(logAppliances ~ ., data = train)
print(model)
data <- read.csv(file = "data/energydata_complete.csv", stringsAsFactors = FALSE)
setwd("C:/Users/rabar/Documents/zum/ZUM-2/Forecasting_appliances_energy_usage")
data <- read.csv(file = "data/energydata_complete.csv", stringsAsFactors = FALSE)
data <- read.csv(file = "data/energydata_complete.csv", stringsAsFactors = FALSE)
data <- read.csv(file = "C:\Users\rabar\Documents\zum\ZUM-2\Forecasting_appliances_energy_usage\data\energydata_complete.csv", stringsAsFactors = FALSE)
data <- read.csv(file = "C:/Users/rabar/Documents/zum/ZUM-2/Forecasting_appliances_energy_usage/data/energydata_complete.csv", stringsAsFactors = FALSE)
data<-data[order(data$date),]
str(data)
#wyliczenia dla kolumn numerycznych
row_names <- colnames(data[,2:29])
mean <- apply(data[,2:29],2, mean)
median <-apply(data[,2:29],2,median)
min <-apply(data[,2:29],2,min)
max<-apply(data[,2:29],2,max)
std<-apply(data[,2:29],2,sd)
number_data.df <- data.frame(row_names, mean, median, min, max, std)
number_data.df[,2:6]<-round(number_data.df[,2:6], 2)
number_data.df[order(number_data.df$row_names),]
# wyliczenia dla date:
mean_date <-mean.Date(as.Date(data[,1:1], format=c("%Y-%m-%d")))
median_date <-median(data[,1:1])
min_date<- min(as.Date(data[,1:1], format=c("%Y-%m-%d")))
max_date<- max(as.Date(data[,1:1], format=c("%Y-%m-%d")))
date_numeric <-as.numeric(as.POSIXct(data[,1:1], format=c("%Y-%m-%d")))
std_date_days<- sd(date_numeric, na.rm = TRUE)/60/60/24
date_data.df <- data.frame("date", mean_date, median_date, min_date, max_date, std_date_days)
#date_data.df[,2:6]<-round(number_data.df[,2:6], 2)
date_data.df
# w ilu kolumnach brakuje danych
which(is.na(data))
# ile jest łącznie brakujących danych
sum(is.na(data))
data1<-as.Date(data$date, format=c("%Y-%m-%d"))
plot(data1,data$Appliances,type="l", col=3, main="Power usage from Appliances in time")
plot(data1,data$lights,type="l", col=3, main="Power usage from lights in time")
install.packages("Hmisc")
library(Hmisc)
data<-data[,order(names(data))]
data_numeric <- subset( data, select = -date )
hist.data.frame(data_numeric[,1:14])
hist.data.frame(data_numeric[,15:28])
library(lubridate)
install.packages("corrplot")
install.packages("lubridate")
install.packages("corrplot")
install.packages("lubridate")
library(lubridate)
library(corrplot)
hour<-hour(as.POSIXct(data[,1:1], format=c("%Y-%m-%d %H:%M:%S")))
library(lubridate)
library(corrplot)
hour<-hour(as.POSIXct(data[,2:2], format=c("%Y-%m-%d %H:%M:%S")))
data_numeric['hour']<-hour
#pory dnia
#22:00 - 6:00 noc 1
#6:00-10:00 rano 2
#10:00-12:00 przedpoludnie 3
#12:00 - 14:00 wczesne popoludnie 4
#14:00 -18:00 popoludnie 5
#18:00 - 22:00 -wieczor 0
time_of_day <- rep(0,length(data$date))
time_of_day[(hour>=22&hour<=24)|(hour>=0&hour<6)]=1
time_of_day[(hour>=6&hour<10)]=2
time_of_day[(hour>=10&hour<12)]=3
time_of_day[(hour>=12&hour<14)]=4
time_of_day[(hour>=14&hour<18)]=5
time_of_day[(hour>=18&hour<22)]=0
data_numeric['time_of_day']<-time_of_day
res <- cor(data_numeric, use = "complete.obs")
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black")
library(lubridate)
library(corrplot)
hour<-hour(as.POSIXct(data[,2:2], format=c("%Y-%m-%d %H:%M:%S")))
data_numeric['hour']<-hour
#pory dnia
#22:00 - 6:00 noc 1
#6:00-10:00 rano 2
#10:00-12:00 przedpoludnie 3
#12:00 - 14:00 wczesne popoludnie 4
#14:00 -18:00 popoludnie 5
#18:00 - 22:00 -wieczor 0
time_of_day <- rep(0,length(data$date))
time_of_day[(hour>=22&hour<=24)|(hour>=0&hour<6)]=1
time_of_day[(hour>=6&hour<10)]=2
time_of_day[(hour>=10&hour<12)]=3
time_of_day[(hour>=12&hour<14)]=4
time_of_day[(hour>=14&hour<18)]=5
time_of_day[(hour>=18&hour<22)]=0
data_numeric['time_of_day']<-time_of_day
day_num<- yday(as.POSIXct(data[,2:2], format=c("%Y-%m-%d %H:%M:%S")))
res <- cor(data_numeric, use = "complete.obs")
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black")
library(lubridate)
library(corrplot)
hour<-hour(as.POSIXct(data[,2:2], format=c("%Y-%m-%d %H:%M:%S")))
data_numeric['hour']<-hour
#pory dnia
#22:00 - 6:00 noc 1
#6:00-10:00 rano 2
#10:00-12:00 przedpoludnie 3
#12:00 - 14:00 wczesne popoludnie 4
#14:00 -18:00 popoludnie 5
#18:00 - 22:00 -wieczor 0
time_of_day <- rep(0,length(data$date))
time_of_day[(hour>=22&hour<=24)|(hour>=0&hour<6)]=1
time_of_day[(hour>=6&hour<10)]=2
time_of_day[(hour>=10&hour<12)]=3
time_of_day[(hour>=12&hour<14)]=4
time_of_day[(hour>=14&hour<18)]=5
time_of_day[(hour>=18&hour<22)]=0
data_numeric['time_of_day']<-time_of_day
data_numeric['day_of_year']<- yday(as.POSIXct(data[,2:2], format=c("%Y-%m-%d %H:%M:%S")))
res <- cor(data_numeric, use = "complete.obs")
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black")
data$logAppliances = log(data$Appliances)
data$logVisibility = log(data$Visibility)
data$logWindspeed = log(data$Windspeed)
data$logRh_out=log(data$Tdewpoint)
data$logT9=log(data$T9)
data$logT3=log(data$T3)
data$logT4=log(data$T4)
data$logT5=log(data$T5)
str(data)
data_numeric <- subset( data, select = -date )
hist.data.frame(data_numeric[,1:14])
hist.data.frame(data_numeric[,15:28])
hist.data.frame(data_numeric[,29:36])
data_numeric$logAppliances = log(data$Appliances)
data_numeric$logVisibility = log(data$Visibility)
data_numeric$logWindspeed = log(data$Windspeed)
data_numeric$logRh_out=log(data$Tdewpoint)
data_numeric$logT9=log(data$T9)
data_numeric$logT3=log(data$T3)
data_numeric$logT4=log(data$T4)
data_numeric$logT5=log(data$T5)
data_numeric[is.na(data_numeric)] = 0
res <- cor(data_numeric, use = "complete.obs")
res[is.na(res)] = 0
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black")
# data_numeric$logAppliances = log(data$Appliances)
# data_numeric$logVisibility = log(data$Visibility)
# data_numeric$logWindspeed = log(data$Windspeed)
# data_numeric$logRh_out=log(data$Tdewpoint)
# data_numeric$logT9=log(data$T9)
# data_numeric$logT3=log(data$T3)
# data_numeric$logT4=log(data$T4)
# data_numeric$logT5=log(data$T5)
# data_numeric[is.na(data_numeric)] = 0
# res <- cor(data_numeric, use = "complete.obs")
# res[is.na(res)] = 0
#
# round(res, 2)
# corrplot(res, type = "full", order = "hclust",
#          tl.col = "black")
data <- read.csv(file = "C:/Users/rabar/Documents/zum/ZUM-2/Forecasting_appliances_energy_usage/data/energydata_complete.csv", stringsAsFactors = FALSE)
data<-data[order(data$date),]
str(data)
#wyliczenia dla kolumn numerycznych
row_names <- colnames(data[,2:29])
mean <- apply(data[,2:29],2, mean)
median <-apply(data[,2:29],2,median)
min <-apply(data[,2:29],2,min)
max<-apply(data[,2:29],2,max)
std<-apply(data[,2:29],2,sd)
number_data.df <- data.frame(row_names, mean, median, min, max, std)
number_data.df[,2:6]<-round(number_data.df[,2:6], 2)
number_data.df[order(number_data.df$row_names),]
# wyliczenia dla date:
mean_date <-mean.Date(as.Date(data[,1:1], format=c("%Y-%m-%d")))
median_date <-median(data[,1:1])
min_date<- min(as.Date(data[,1:1], format=c("%Y-%m-%d")))
max_date<- max(as.Date(data[,1:1], format=c("%Y-%m-%d")))
date_numeric <-as.numeric(as.POSIXct(data[,1:1], format=c("%Y-%m-%d")))
std_date_days<- sd(date_numeric, na.rm = TRUE)/60/60/24
date_data.df <- data.frame("date", mean_date, median_date, min_date, max_date, std_date_days)
#date_data.df[,2:6]<-round(number_data.df[,2:6], 2)
date_data.df
# w ilu kolumnach brakuje danych
which(is.na(data))
# ile jest łącznie brakujących danych
sum(is.na(data))
data1<-as.Date(data$date, format=c("%Y-%m-%d"))
plot(data1,data$Appliances,type="l", col=3, main="Power usage from Appliances in time")
plot(data1,data$lights,type="l", col=3, main="Power usage from lights in time")
data<-data[,order(names(data))]
data_numeric <- subset( data, select = -date )
hist.data.frame(data_numeric[,1:14])
hist.data.frame(data_numeric[,15:28])
for (i in 1:ncol(data_numeric[,1: ncol(data_numeric) ])){
qqnorm(data_numeric[, i], main = names(data_numeric[i]), col=3)
qqline(data_numeric[, i])
}
library(lubridate)
library(corrplot)
hour<-hour(as.POSIXct(data[,2:2], format=c("%Y-%m-%d %H:%M:%S")))
data_numeric['hour']<-hour
#pory dnia
#22:00 - 6:00 noc 1
#6:00-10:00 rano 2
#10:00-12:00 przedpoludnie 3
#12:00 - 14:00 wczesne popoludnie 4
#14:00 -18:00 popoludnie 5
#18:00 - 22:00 -wieczor 0
time_of_day <- rep(0,length(data$date))
time_of_day[(hour>=22&hour<=24)|(hour>=0&hour<6)]=1
time_of_day[(hour>=6&hour<10)]=2
time_of_day[(hour>=10&hour<12)]=3
time_of_day[(hour>=12&hour<14)]=4
time_of_day[(hour>=14&hour<18)]=5
time_of_day[(hour>=18&hour<22)]=0
data_numeric['time_of_day']<-time_of_day
data_numeric['day_of_year']<- yday(as.POSIXct(data[,2:2], format=c("%Y-%m-%d %H:%M:%S")))
res <- cor(data_numeric, use = "complete.obs")
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black")
data$logAppliances = log(data$Appliances)
data$logVisibility = log(data$Visibility)
data$logWindspeed = log(data$Windspeed)
data$logRh_out=log(data$Tdewpoint)
data$logT9=log(data$T9)
data$logT3=log(data$T3)
data$logT4=log(data$T4)
data$logT5=log(data$T5)
str(data)
data_numeric <- subset( data, select = -date )
hist.data.frame(data_numeric[,1:14])
hist.data.frame(data_numeric[,15:28])
hist.data.frame(data_numeric[,29:36])
write.csv(data_numeric,'../data/energy_data_after_analysis.csv')
data <- read.csv(file = "C:/Users/rabar/Documents/zum/ZUM-2/Forecasting_appliances_energy_usage/data/energydata_complete.csv", stringsAsFactors = FALSE)
data<-data[order(data$date),]
str(data)
#wyliczenia dla kolumn numerycznych
row_names <- colnames(data[,2:29])
mean <- apply(data[,2:29],2, mean)
median <-apply(data[,2:29],2,median)
min <-apply(data[,2:29],2,min)
max<-apply(data[,2:29],2,max)
std<-apply(data[,2:29],2,sd)
number_data.df <- data.frame(row_names, mean, median, min, max, std)
number_data.df[,2:6]<-round(number_data.df[,2:6], 2)
number_data.df[order(number_data.df$row_names),]
# wyliczenia dla date:
mean_date <-mean.Date(as.Date(data[,1:1], format=c("%Y-%m-%d")))
median_date <-median(data[,1:1])
min_date<- min(as.Date(data[,1:1], format=c("%Y-%m-%d")))
max_date<- max(as.Date(data[,1:1], format=c("%Y-%m-%d")))
date_numeric <-as.numeric(as.POSIXct(data[,1:1], format=c("%Y-%m-%d")))
std_date_days<- sd(date_numeric, na.rm = TRUE)/60/60/24
date_data.df <- data.frame("date", mean_date, median_date, min_date, max_date, std_date_days)
#date_data.df[,2:6]<-round(number_data.df[,2:6], 2)
date_data.df
# w ilu kolumnach brakuje danych
which(is.na(data))
# ile jest łącznie brakujących danych
sum(is.na(data))
data<-data[,order(names(data))]
data_numeric <- subset( data, select = -date )
hist.data.frame(data_numeric[,1:14])
hist.data.frame(data_numeric[,15:28])
library(lubridate)
library(corrplot)
hour<-hour(as.POSIXct(data[,2:2], format=c("%Y-%m-%d %H:%M:%S")))
data_numeric['hour']<-hour
#pory dnia
#22:00 - 6:00 noc 1
#6:00-10:00 rano 2
#10:00-12:00 przedpoludnie 3
#12:00 - 14:00 wczesne popoludnie 4
#14:00 -18:00 popoludnie 5
#18:00 - 22:00 -wieczor 0
time_of_day <- rep(0,length(data$date))
time_of_day[(hour>=22&hour<=24)|(hour>=0&hour<6)]=1
time_of_day[(hour>=6&hour<10)]=2
time_of_day[(hour>=10&hour<12)]=3
time_of_day[(hour>=12&hour<14)]=4
time_of_day[(hour>=14&hour<18)]=5
time_of_day[(hour>=18&hour<22)]=0
data_numeric['time_of_day']<-time_of_day
data_numeric['day_of_year']<- yday(as.POSIXct(data[,2:2], format=c("%Y-%m-%d %H:%M:%S")))
res <- cor(data_numeric, use = "complete.obs")
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black")
write.csv(data_numeric,'../data/energy_data_after_analysis.csv')
data <- read.csv(file = "../data/energy_data_after_analysis.csv", stringsAsFactors = FALSE)
str(data)
# w ilu kolumnach brakuje danych
which(is.na(data))
# ile jest łącznie brakujących danych
sum(is.na(data))
mising<-data[is.na(data),]
data = na.omit(data)
#data[is.na(data)] = 0
library(lubridate)
library(corrplot)
library(Hmisc)
data$logAppliances = log(data$Appliances)
#data$logVisibility = log(data$Visibility)
#data$logWindspeed = log(data$Windspeed)
#data$logRh_out=log(data$Tdewpoint)
#data$logT9=log(data$T9)
#data$logT3=log(data$T3)
#data$logT4=log(data$T4)
#data$logT5=log(data$T5)
res <- cor(data, use = "complete.obs")
res[is.na(res)] = 0
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black")
data <- read.csv(file = "../data/energy_data_after_analysis.csv", stringsAsFactors = FALSE)
str(data)
# w ilu kolumnach brakuje danych
which(is.na(data))
# ile jest łącznie brakujących danych
sum(is.na(data))
mising<-data[is.na(data),]
data = na.omit(data)
#data[is.na(data)] = 0
library(lubridate)
library(corrplot)
library(Hmisc)
data$logAppliances = log(data$Appliances)
data$logVisibility = log(data$Visibility)
data$logWindspeed = log(data$Windspeed)
data$logRh_out=log(data$Tdewpoint)
data$logT9=log(data$T9)
data$logT3=log(data$T3)
data$logT4=log(data$T4)
data$logT5=log(data$T5)
res <- cor(data, use = "complete.obs")
res[is.na(res)] = 0
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black")
data <- read.csv(file = "../data/energy_data_after_analysis.csv", stringsAsFactors = FALSE)
str(data)
# w ilu kolumnach brakuje danych
which(is.na(data))
# ile jest łącznie brakujących danych
sum(is.na(data))
mising<-data[is.na(data),]
data = na.omit(data)
#data[is.na(data)] = 0
library(lubridate)
library(corrplot)
library(Hmisc)
data$logAppliances = log(data$Appliances)
data$logVisibility = log(data$Visibility)
data$logWindspeed = log(data$Windspeed)
data$logRh_out=log(data$Tdewpoint)
data$logT9=log(data$T9)
data$logT3=log(data$T3)
data$logT4=log(data$T4)
data$logT5=log(data$T5)
res <- cor(data, use = "complete.obs")
res[is.na(res)] = 0
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black")
atributes <- data[,!names(data) %in% c("date", "logRh_out", "logWindspeed","X","T3","T4","T5","T9","Tdewpoint","rv1","rv2","RH_5","RH_3","RH_4","Windspeed","Visibility","logVisibility","Appliances","logAppliances","logVisibility","logWindspeed","logRh_out","logT9","logT3","logT4","logT5")]
atributes_with_interactions = model.matrix(~(lights+Press_mm_hg+RH_1+RH_2+RH_6+RH_7+RH_8+RH_9+RH_out+T_out+T1+T2+T6+T7+T8+hour+time_of_day)^2,atributes)
corr_data = as.data.frame(atributes_with_interactions)
corr_data$logAppliances = data$logAppliances
library(lubridate)
library(corrplot)
res <- cor(corr_data, use = "complete.obs")
res[is.na(res)] = 0
round(res, 2)
res = as.data.frame(res)
res[abs(res$logAppliances) > 0.4] # nie istnieja korelacje wieksze od 0.4,
atributes = scale(atributes)
boruta_atributes = as.data.frame(atributes)
boruta_atributes$logAppliances = data$logAppliances
boruta_atributes = as.data.frame(boruta_atributes)
str(boruta_atributes)
#install.packages("Boruta")
library(Boruta)
write.csv(atributes, '../data/energy_data_after_processing.csv')
library(caret)
install.packages("caret")
library(caret)
library(caret)
library(caret)
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
library(caret)
